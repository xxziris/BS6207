{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BS6207_Assignment1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "mount_file_id": "1eVrQnGprTHMCgEdOlpiFzOZplCT3ElOV",
      "authorship_tag": "ABX9TyO94BeCj1bYsIKwFMgluQpe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/xxziris/BS6207/blob/main/BS6207_Assignment1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WizRjg3Bz_R_"
      },
      "source": [
        "# BS6207 Assignment 1\n",
        "\n",
        "Xinxin <br>\n",
        "Mar/2021\n",
        "\n",
        "----\n",
        "\n",
        "Given a fully connected Neural Network as follows: <br>\n",
        "1. Input (x1,x2): 2 nodes\n",
        "2. First hidden layer: 10 nodes, with weights (w) and bias (b), sigmoid activation function\n",
        "3. Second hidden layer: 10 nodes, with weights (w) and bias (b), sigmoid activation function\n",
        "4. Output (predict): 1 node\n",
        "\n",
        "__Requirements:__ <br>\n",
        "1. Implement this neural network in pytorch\n",
        "2. Generate the input date (x1,x2) \\in [0,1] drawn from a uniform random distribution\n",
        "3. Generate the labels y = (x1*x1+x2*x2)/2\n",
        "4. Implement a loss function L = (predict-y)^2\n",
        "5. Use batch size of 1, that means feed data one point at a time into network and compute the loss. Do one time forward propagation with one data point.\n",
        "6. Compute the gradients using pytorch autograd:\n",
        "    - dL/dw, dL/db\n",
        "    - Print these values into a text file: torch_autograd.dat\n",
        "7. Implement the forward propagation and backpropagation algorithm from scratch, without using pytorch autograd, compute the gradients using your implementation\n",
        "    - dL/dw, dL/db\n",
        "    - Print these values into a text file: my_autograd.dat\n",
        "8. Compare the two files torch_autograd.dat and my_autograd.dat and show that they give\n",
        "the same values up to numerical precision errors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2NWAWBCozmjK"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import random"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pvvGyb1S5V9-",
        "outputId": "a6b54d47-a694-4dcb-c3e6-a30b2aae747c"
      },
      "source": [
        "# 1. implement the neural network in pytorch\n",
        "class Net(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Net, self).__init__()\n",
        "    self.fc1 = nn.Linear(2, 10)\n",
        "    self.fc2 = nn.Linear(10, 10)\n",
        "    self.fc3 = nn.Linear(10, 1)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = torch.sigmoid(self.fc1(x))\n",
        "    x = torch.sigmoid(self.fc2(x))\n",
        "    return self.fc3(x)\n",
        "\n",
        "net = Net()\n",
        "print(net)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Net(\n",
            "  (fc1): Linear(in_features=2, out_features=10, bias=True)\n",
            "  (fc2): Linear(in_features=10, out_features=10, bias=True)\n",
            "  (fc3): Linear(in_features=10, out_features=1, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5-6581Ml22cz"
      },
      "source": [
        "random.seed(127)\n",
        "# 2. generate input data x1 x2 from uniform random distribution of [0,1]\n",
        "input = torch.rand(1,2, requires_grad = False)\n",
        "\n",
        "# 3. generate the labels of input data\n",
        "y = (input[0][0]**2 + input[0][1]**2)/2"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oncYuiAk5YaS"
      },
      "source": [
        "# 4. define loss function\n",
        "def my_loss(output, target):\n",
        "  loss = (output - target)**2\n",
        "  return loss"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-4dn7f2IqhBT"
      },
      "source": [
        "# 5. One time forward propagation with one data point\n",
        "y_pred = net(input)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gzb7Zs-Kqs5T"
      },
      "source": [
        "# 6. compute dL/dw, dL/db using pytorch autograd\n",
        "loss = my_loss(y_pred, y)\n",
        "loss.backward(retain_graph = True)\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CyjMYt90eoC2",
        "outputId": "b0183364-9e8a-4e15-b41d-d2272a01f625"
      },
      "source": [
        "loss"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.1411]], grad_fn=<PowBackward0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rD4XrK1QV6yk",
        "outputId": "22774980-258b-4abe-accc-0891943998c5"
      },
      "source": [
        "# print dL/dw to check\n",
        "print('dL/dw3 = ', net.fc3.weight.grad)\n",
        "print('dL/dw2 = ', net.fc2.weight.grad)\n",
        "print('dL/dw1 = ', net.fc1.weight.grad)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dL/dw3 =  tensor([[-0.3391, -0.3071, -0.3031, -0.3271, -0.3050, -0.4498, -0.4268, -0.3326,\n",
            "         -0.3236, -0.2691]])\n",
            "dL/dw2 =  tensor([[-0.0027, -0.0027, -0.0030, -0.0027, -0.0036, -0.0031, -0.0016, -0.0040,\n",
            "         -0.0026, -0.0017],\n",
            "        [-0.0203, -0.0208, -0.0232, -0.0203, -0.0273, -0.0233, -0.0121, -0.0302,\n",
            "         -0.0201, -0.0129],\n",
            "        [ 0.0042,  0.0043,  0.0048,  0.0042,  0.0056,  0.0048,  0.0025,  0.0062,\n",
            "          0.0041,  0.0027],\n",
            "        [-0.0014, -0.0015, -0.0016, -0.0014, -0.0019, -0.0016, -0.0009, -0.0021,\n",
            "         -0.0014, -0.0009],\n",
            "        [-0.0059, -0.0060, -0.0067, -0.0059, -0.0079, -0.0067, -0.0035, -0.0087,\n",
            "         -0.0058, -0.0037],\n",
            "        [ 0.0213,  0.0218,  0.0243,  0.0213,  0.0286,  0.0245,  0.0127,  0.0317,\n",
            "          0.0211,  0.0135],\n",
            "        [ 0.0130,  0.0133,  0.0149,  0.0130,  0.0175,  0.0150,  0.0078,  0.0194,\n",
            "          0.0129,  0.0083],\n",
            "        [-0.0113, -0.0116, -0.0129, -0.0113, -0.0152, -0.0130, -0.0067, -0.0168,\n",
            "         -0.0112, -0.0072],\n",
            "        [-0.0117, -0.0119, -0.0133, -0.0117, -0.0157, -0.0134, -0.0069, -0.0173,\n",
            "         -0.0115, -0.0074],\n",
            "        [ 0.0212,  0.0217,  0.0242,  0.0212,  0.0285,  0.0244,  0.0126,  0.0315,\n",
            "          0.0210,  0.0135]])\n",
            "dL/dw1 =  tensor([[ 0.0014,  0.0042],\n",
            "        [ 0.0002,  0.0006],\n",
            "        [ 0.0034,  0.0104],\n",
            "        [ 0.0009,  0.0027],\n",
            "        [-0.0003, -0.0010],\n",
            "        [-0.0017, -0.0051],\n",
            "        [-0.0007, -0.0023],\n",
            "        [ 0.0011,  0.0035],\n",
            "        [-0.0003, -0.0011],\n",
            "        [ 0.0017,  0.0053]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ObiHJ8dvBSY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6a339de-88ef-40c6-e466-66d288dbaa8b"
      },
      "source": [
        "# print dL/db to check\n",
        "print('dL/db3 = ', net.fc3.bias.grad)\n",
        "print('dL/db2 = ', net.fc2.bias.grad)\n",
        "print('dL/db1 = ', net.fc1.bias.grad)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dL/db3 =  tensor([-0.7513])\n",
            "dL/db2 =  tensor([-0.0063, -0.0481,  0.0099, -0.0034, -0.0139,  0.0505,  0.0309, -0.0268,\n",
            "        -0.0276,  0.0502])\n",
            "dL/db1 =  tensor([ 0.0043,  0.0006,  0.0106,  0.0027, -0.0010, -0.0052, -0.0023,  0.0035,\n",
            "        -0.0011,  0.0054])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8U6VV75Y3QIq"
      },
      "source": [
        "# write the gradiet to torch_autograd.dat\n",
        "with open('/content/drive/MyDrive/Colab Notebooks/BS6207/Assignment1/torch_autograd.dat',\"w\") as file:\n",
        "  file.write('\\ndLdw3\\n')\n",
        "  file.write(np.array2string(net.fc3.weight.grad.data.numpy(), precision = 7, separator = ','))\n",
        "  file.write('\\ndLdw2\\n')\n",
        "  file.write(np.array2string(net.fc2.weight.grad.data.numpy(), precision = 7, separator = ','))\n",
        "  file.write('\\ndLdw1\\n')\n",
        "  file.write(np.array2string(net.fc1.weight.grad.data.numpy(), precision = 7, separator = ','))\n",
        "  file.write('\\ndLdb3\\n')\n",
        "  file.write(np.array2string(net.fc3.bias.grad.data.numpy(), precision = 7, separator = ','))\n",
        "  file.write('\\ndLdb2\\n')\n",
        "  file.write(np.array2string(net.fc2.bias.grad.data.numpy(), precision = 7, separator = ','))\n",
        "  file.write('\\ndLdb1\\n')\n",
        "  file.write(np.array2string(net.fc1.bias.grad.data.numpy(), precision = 7, separator = ','))\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WjePJt-LFENK"
      },
      "source": [
        "# 7. Implement forward propagation and backward propagation from scratch\n",
        "# get the same weight and bias from the model above\n",
        "w1 = net.fc1.weight\n",
        "w2 = net.fc2.weight\n",
        "w3 = net.fc3.weight\n",
        "\n",
        "b1 = net.fc1.bias\n",
        "b2 = net.fc2.bias\n",
        "b3 = net.fc3.bias"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i-66IlXQtzKU"
      },
      "source": [
        "# define the sigmoid activation function from scratch\n",
        "def sigmoid(input):\n",
        "  return 1/(1 + torch.exp(-input))"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jfv6tnsq0fh0"
      },
      "source": [
        "# define function for derivative of sigmoid\n",
        "def sigmoid_der(input):\n",
        "  s = sigmoid(input)\n",
        "  return torch.transpose(s*(1-s), 0, 1)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lEmdhbp5Pv4e"
      },
      "source": [
        "# forward propagation\n",
        "\n",
        "# first layer\n",
        "z1 = torch.mm(input, torch.transpose(w1,0,1)) + b1\n",
        "h1 = sigmoid(z1)\n",
        "# second layer\n",
        "z2 = torch.mm(h1, torch.transpose(w2,0,1)) + b2\n",
        "h2 = sigmoid(z2)\n",
        "# output\n",
        "h3 = torch.mm(h2, torch.transpose(w3,0,1)) + b3"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nc-38mwCvYn2",
        "outputId": "232929f7-a3ad-4665-aa7f-bb88829d6ffe"
      },
      "source": [
        "# backward propagation\n",
        "loss_2 = my_loss(h3, y)\n",
        "loss_2 # same as the loss from the model above"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.1411]], grad_fn=<PowBackward0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uCWfcAb0eroI",
        "outputId": "0c5ee49e-c654-4ded-efe0-cb5a116bcbd1"
      },
      "source": [
        "# check if the output is the same as the model above\n",
        "print(h3, y_pred)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.1632]], grad_fn=<AddBackward0>) tensor([[0.1632]], grad_fn=<AddmmBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TMHlQxJjvYdu",
        "outputId": "b4715ca7-5d71-4d29-afbd-0c2cd2c8cd9c"
      },
      "source": [
        "# calculate dL/dw3\n",
        "dL_dw3 = 2 * (h3 - y) * h2\n",
        "dL_dw3"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.3391, -0.3071, -0.3031, -0.3271, -0.3050, -0.4498, -0.4268, -0.3326,\n",
              "         -0.3236, -0.2691]], grad_fn=<MulBackward0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-4HIcuHwP2WY",
        "outputId": "7478fd7b-91c3-4afd-cd18-fb41a50b4ed5"
      },
      "source": [
        "# calculate dL/dw2\n",
        "dL_dw2 =  2 * (h3 - y) * torch.transpose(w3, 0, 1) @ h1 * sigmoid_der(z2)\n",
        "dL_dw2"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.0027, -0.0027, -0.0030, -0.0027, -0.0036, -0.0031, -0.0016, -0.0040,\n",
              "         -0.0026, -0.0017],\n",
              "        [-0.0203, -0.0208, -0.0232, -0.0203, -0.0273, -0.0233, -0.0121, -0.0302,\n",
              "         -0.0201, -0.0129],\n",
              "        [ 0.0042,  0.0043,  0.0048,  0.0042,  0.0056,  0.0048,  0.0025,  0.0062,\n",
              "          0.0041,  0.0027],\n",
              "        [-0.0014, -0.0015, -0.0016, -0.0014, -0.0019, -0.0016, -0.0009, -0.0021,\n",
              "         -0.0014, -0.0009],\n",
              "        [-0.0059, -0.0060, -0.0067, -0.0059, -0.0079, -0.0067, -0.0035, -0.0087,\n",
              "         -0.0058, -0.0037],\n",
              "        [ 0.0213,  0.0218,  0.0243,  0.0213,  0.0286,  0.0245,  0.0127,  0.0317,\n",
              "          0.0211,  0.0135],\n",
              "        [ 0.0130,  0.0133,  0.0149,  0.0130,  0.0175,  0.0150,  0.0078,  0.0194,\n",
              "          0.0129,  0.0083],\n",
              "        [-0.0113, -0.0116, -0.0129, -0.0113, -0.0152, -0.0130, -0.0067, -0.0168,\n",
              "         -0.0112, -0.0072],\n",
              "        [-0.0117, -0.0119, -0.0133, -0.0117, -0.0157, -0.0134, -0.0069, -0.0173,\n",
              "         -0.0115, -0.0074],\n",
              "        [ 0.0212,  0.0217,  0.0242,  0.0212,  0.0285,  0.0244,  0.0126,  0.0315,\n",
              "          0.0210,  0.0135]], grad_fn=<MulBackward0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vGKxLS7usueg",
        "outputId": "36292946-ebf3-438f-c2ae-00e443104c1a"
      },
      "source": [
        "# calculate dL/dw1\n",
        "dL_dw1 = torch.transpose(torch.transpose(2 * (h3 - y) * torch.transpose(w3, 0, 1) * sigmoid_der(z2) , 0,1 ) @ w2, 0,1) @ input * sigmoid_der(z1)\n",
        "dL_dw1"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.0014,  0.0042],\n",
              "        [ 0.0002,  0.0006],\n",
              "        [ 0.0034,  0.0104],\n",
              "        [ 0.0009,  0.0027],\n",
              "        [-0.0003, -0.0010],\n",
              "        [-0.0017, -0.0051],\n",
              "        [-0.0007, -0.0023],\n",
              "        [ 0.0011,  0.0035],\n",
              "        [-0.0003, -0.0011],\n",
              "        [ 0.0017,  0.0053]], grad_fn=<MulBackward0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IttfW5QBgrAq",
        "outputId": "6796404d-e674-4a51-bb35-1cfd2f7a84be"
      },
      "source": [
        "# calculate dL/db3\n",
        "dL_db3 = 2 * (h3 - y)\n",
        "dL_db3"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.7513]], grad_fn=<MulBackward0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WERHZYQd8SGx",
        "outputId": "9d63a0d6-12b6-4dd3-c92d-ce108b4795e8"
      },
      "source": [
        "# calculate dL/db2\n",
        "dL_db2 = torch.transpose(2 * (h3 - y) * torch.transpose(w3, 0, 1) * sigmoid_der(z2), 0, 1)\n",
        "dL_db2"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.0063, -0.0481,  0.0099, -0.0034, -0.0139,  0.0505,  0.0309, -0.0268,\n",
              "         -0.0276,  0.0502]], grad_fn=<TransposeBackward0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IdvQvYXM8kBr",
        "outputId": "72911e54-08fd-48cb-fd20-8cb1e3da2eb5"
      },
      "source": [
        "# calculate dL/db1\n",
        "dL_db1 = torch.transpose(torch.transpose(torch.transpose(2 * (h3 - y) * torch.transpose(w3, 0, 1) * sigmoid_der(z2), 0, 1) @ w2, 0, 1) * sigmoid_der(z1), 0, 1)\n",
        "dL_db1"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.0043,  0.0006,  0.0106,  0.0027, -0.0010, -0.0052, -0.0023,  0.0035,\n",
              "         -0.0011,  0.0054]], grad_fn=<TransposeBackward0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-6hqghMljlML"
      },
      "source": [
        "# output the calculated gradient to my_autograd.dat\n",
        "with open('/content/drive/MyDrive/Colab Notebooks/BS6207/Assignment1/my_autograd.dat',\"w\") as file:\n",
        "  file.write('\\ndLdw3\\n')\n",
        "  file.write(np.array2string(dL_dw3.data.numpy(), precision = 7, separator = ','))\n",
        "  file.write('\\ndLdw2\\n')\n",
        "  file.write(np.array2string(dL_dw2.data.numpy(), precision = 7, separator = ','))\n",
        "  file.write('\\ndLdw1\\n')\n",
        "  file.write(np.array2string(dL_dw1.data.numpy(), precision = 7, separator = ','))\n",
        "  file.write('\\ndLdb3\\n')\n",
        "  file.write(np.array2string(dL_db3.data.numpy()[0], precision = 7, separator = ','))\n",
        "  file.write('\\ndLdb2\\n')\n",
        "  file.write(np.array2string(dL_db2.data.numpy()[0], precision = 7, separator = ','))\n",
        "  file.write('\\ndLdb1\\n')\n",
        "  file.write(np.array2string(dL_db1.data.numpy()[0], precision = 7, separator = ','))"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5bj5hyw0t4da"
      },
      "source": [
        "By comparing the two output files, the loss function has the same gradient against weights and biases from the pytorch model and the self-constructed model."
      ]
    }
  ]
}